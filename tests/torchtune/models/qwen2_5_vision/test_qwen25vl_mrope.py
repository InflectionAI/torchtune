#!/usr/bin/env python3

import pytest
import torch
from torchtune.models.qwen2_5_vision._positional_embeddings import Qwen25VLRotaryPositionalEmbeddings


class TestQwen25VLMRoPE:
    """
    Test MRoPE implementation against Qwen2.5-VL reference tensors.
    
    This test loads reference tensors generated by running the HuggingFace
    transformers implementation and compares against our torchtune implementation.
    """

    @pytest.fixture
    def qwen25vl_config(self):
        """
        Real Qwen2.5-VL-7B model configuration parameters for MRoPE.
        Based on actual config.json and tensor shapes from reference data.
        """
        return {
            "dim": 128,  # head_dim = hidden_size // num_heads = 3584 // 28 = 128
            "mrope_section": [16, 24, 24],  # actual Qwen2.5-VL mrope sections  
            "max_seq_len": 128000,  # from config.json
            "base": 1000000.0,  # rope_theta from config.json
        }

    @pytest.fixture(params=["text_only", "text_image", "text_video"])
    def modality_case(self, request):
        """Parameterized fixture for different input modalities."""
        return request.param

    @pytest.fixture
    def reference_tensors(self, modality_case):
        """
        Load reference tensors from HuggingFace implementation for specific modality.
        """
        tensors_path = f"/mnt/vast/home/lawrence/tensors/{modality_case}"
        
        try:
            return {
                "position_ids": torch.load(f"{tensors_path}/position_ids.pt"),
                "rope_input_x": torch.load(f"{tensors_path}/rope_input_x.pt"),
                "rope_input_position_ids": torch.load(f"{tensors_path}/rope_input_position_ids.pt"),
                "rope_output_cos_sin": torch.load(f"{tensors_path}/rope_output_cos_sin.pt"),
                "position_embeddings": torch.load(f"{tensors_path}/position_embeddings.pt"),
                "mrope_input_q": torch.load(f"{tensors_path}/mrope_input_q.pt"),
                "mrope_input_k": torch.load(f"{tensors_path}/mrope_input_k.pt"),
                "mrope_input_cos": torch.load(f"{tensors_path}/mrope_input_cos.pt"),
                "mrope_input_sin": torch.load(f"{tensors_path}/mrope_input_sin.pt"),
                "mrope_section": torch.load(f"{tensors_path}/mrope_section.pt"),
                "q_embed": torch.load(f"{tensors_path}/q_embed.pt"),
                "k_embed": torch.load(f"{tensors_path}/k_embed.pt"),
            }
        except FileNotFoundError as e:
            pytest.skip(f"Reference tensors not found for {modality_case}: {e}")

    @pytest.fixture
    def mrope_model(self, qwen25vl_config):
        """Create MRoPE model with Qwen2.5-VL config."""
        return Qwen25VLRotaryPositionalEmbeddings(**qwen25vl_config)

    def test_position_ids_shape_and_pattern(self, reference_tensors, modality_case):
        """
        Test position_ids shape and validate patterns for different modalities.
        """
        position_ids = reference_tensors["position_ids"]
        
        # Should be shape [3, batch_size, seq_length]
        assert position_ids.dim() == 3
        assert position_ids.shape[0] == 3  # temporal, height, width
        
        # Extract the three dimensions
        temporal_ids = position_ids[0]  # [batch_size, seq_length] 
        height_ids = position_ids[1]    # [batch_size, seq_length]
        width_ids = position_ids[2]     # [batch_size, seq_length]
        
        print(f"✓ Position IDs shape: {position_ids.shape} for {modality_case}")
        print(f"  Temporal range: {temporal_ids.min().item()} to {temporal_ids.max().item()}")
        print(f"  Height range: {height_ids.min().item()} to {height_ids.max().item()}")
        print(f"  Width range: {width_ids.min().item()} to {width_ids.max().item()}")
        
        if modality_case == "text_only":
            # For text-only input, all 3 dimensions should be identical
            torch.testing.assert_close(temporal_ids, height_ids)
            torch.testing.assert_close(temporal_ids, width_ids)
            print(f"✓ All dimensions identical for text-only input")
        else:
            # For multimodal inputs, dimensions should be different
            # (This is the key improvement in Qwen2.5-VL MRoPE)
            print(f"✓ Multimodal position patterns detected for {modality_case}")

    def test_rope_input_output_consistency(self, reference_tensors):
        """
        Test that the inputs and outputs of the rotary embedding are consistent.
        """
        rope_input_x = reference_tensors["rope_input_x"]
        rope_input_position_ids = reference_tensors["rope_input_position_ids"] 
        rope_output_cos_sin = reference_tensors["rope_output_cos_sin"]
        position_embeddings = reference_tensors["position_embeddings"]
        
        # rope_output_cos_sin and position_embeddings should be the same
        cos_ref, sin_ref = rope_output_cos_sin
        cos_pe, sin_pe = position_embeddings
        
        torch.testing.assert_close(cos_ref, cos_pe)
        torch.testing.assert_close(sin_ref, sin_pe)
        
        print(f"✓ RoPE outputs consistent")
        print(f"✓ cos shape: {cos_ref.shape}, sin shape: {sin_ref.shape}")

    def test_mrope_dimensions(self, reference_tensors, qwen25vl_config):
        """
        Test that MRoPE section dimensions are correct.
        """
        mrope_section = reference_tensors["mrope_section"]
        expected_sections = qwen25vl_config["mrope_section"]
        
        # Convert tensor to list for comparison
        if isinstance(mrope_section, torch.Tensor):
            mrope_section_list = mrope_section.tolist()
        else:
            mrope_section_list = mrope_section
        
        # IMPORTANT: In HF code, mrope_section * 2 performs LIST CONCATENATION, not element multiplication!
        # [16, 24, 24] * 2 = [16, 24, 24, 16, 24, 24] (list concatenation)
        # NOT [32, 48, 48] (element-wise multiplication)
        expected_concatenated = expected_sections * 2  # [16, 24, 24, 16, 24, 24]
        
        print(f"Original sections: {expected_sections}")
        print(f"After mrope_section * 2: {expected_concatenated}")
        print(f"Actual saved: {mrope_section_list}")
        
        # The saved mrope_section should match the concatenated version
        assert mrope_section_list == expected_concatenated
        
        print(f"✓ MRoPE sections: {expected_sections} -> {expected_concatenated} (list concatenation)")

    def test_torchtune_vs_huggingface(self, reference_tensors, qwen25vl_config, modality_case):
        """
        Compare torchtune MRoPE implementation against HuggingFace reference for all modalities.
        """
        from torchtune.models.qwen2_5_vision._positional_embeddings import apply_multimodal_rotary_pos_emb
        
        # Get reference data
        ref_q = reference_tensors["mrope_input_q"]       
        ref_k = reference_tensors["mrope_input_k"]       
        ref_cos = reference_tensors["mrope_input_cos"]   
        ref_sin = reference_tensors["mrope_input_sin"]   
        ref_q_embed = reference_tensors["q_embed"]       
        ref_k_embed = reference_tensors["k_embed"]       
        mrope_section = qwen25vl_config["mrope_section"] 
        
        print(f"\n=== Testing {modality_case} ===")
        print(f"Reference tensor shapes:")
        print(f"  q: {ref_q.shape}, k: {ref_k.shape}")
        print(f"  cos: {ref_cos.shape}, sin: {ref_sin.shape}")
        print(f"  q_embed: {ref_q_embed.shape}, k_embed: {ref_k_embed.shape}")
        print(f"  mrope_section: {mrope_section}")
        
        # Expand cos/sin to match expected format [3, batch_size, seq_len, head_dim]
        cos_expanded = ref_cos.expand(3, -1, -1, -1)  
        sin_expanded = ref_sin.expand(3, -1, -1, -1)  
        
        # Apply our torchtune implementation
        try:
            our_q_embed, our_k_embed = apply_multimodal_rotary_pos_emb(
                ref_q, ref_k, cos_expanded, sin_expanded, mrope_section, unsqueeze_dim=1
            )
            
            print(f"Our output shapes - q_embed: {our_q_embed.shape}, k_embed: {our_k_embed.shape}")
            
            # Compare results
            q_close = torch.allclose(our_q_embed, ref_q_embed, atol=1e-5, rtol=1e-4)
            k_close = torch.allclose(our_k_embed, ref_k_embed, atol=1e-5, rtol=1e-4)
            
            print(f"Comparison results:")
            print(f"  Q embeddings match: {q_close}")
            print(f"  K embeddings match: {k_close}")
            
            if not q_close:
                q_diff = torch.abs(our_q_embed - ref_q_embed)
                print(f"  Q max diff: {q_diff.max().item():.2e}")
                print(f"  Q mean diff: {q_diff.mean().item():.2e}")
                
            if not k_close:
                k_diff = torch.abs(our_k_embed - ref_k_embed)
                print(f"  K max diff: {k_diff.max().item():.2e}")
                print(f"  K mean diff: {k_diff.mean().item():.2e}")
            
            # Assert that our implementation matches the reference
            assert q_close, f"Q embeddings don't match HuggingFace reference for {modality_case}"
            assert k_close, f"K embeddings don't match HuggingFace reference for {modality_case}"
            
            print(f"✓ Torchtune MRoPE implementation matches HuggingFace for {modality_case}!")
            
        except Exception as e:
            print(f"✗ Error in torchtune implementation for {modality_case}: {e}")
            import traceback
            traceback.print_exc()
            pytest.fail(f"Torchtune MRoPE implementation failed for {modality_case}: {e}")

    def test_tensor_loading(self, reference_tensors, modality_case):
        """
        Simple test to verify all reference tensors can be loaded for each modality.
        """
        required_tensors = [
            "position_ids", "rope_input_x", "rope_input_position_ids", 
            "rope_output_cos_sin", "position_embeddings", "mrope_input_q",
            "mrope_input_k", "mrope_input_cos", "mrope_input_sin", 
            "mrope_section", "q_embed", "k_embed"
        ]
        
        for tensor_name in required_tensors:
            assert tensor_name in reference_tensors, f"Missing tensor: {tensor_name}"
            tensor = reference_tensors[tensor_name]
            assert tensor is not None, f"Tensor {tensor_name} is None"
            
        print(f"✓ All {len(required_tensors)} reference tensors loaded successfully for {modality_case}")

    def test_mrope_section_fix(self):
        """
        Test that our torchtune implementation correctly handles mrope_section.
        """
        from torchtune.models.qwen2_5_vision._positional_embeddings import apply_multimodal_rotary_pos_emb
        
        # Test the fixed behavior
        original_section = [16, 24, 24]
        
        # Create dummy cos/sin tensors with correct total dimension
        total_dim = sum(original_section * 2)  # 16+24+24+16+24+24 = 128
        batch_size, seq_len = 1, 6
        cos = torch.randn(3, batch_size, seq_len, total_dim)  # Match HF format
        sin = torch.randn(3, batch_size, seq_len, total_dim)
        
        # Create dummy q, k tensors
        num_heads, head_dim = 28, 128
        q = torch.randn(batch_size, num_heads, seq_len, head_dim)
        k = torch.randn(batch_size, 4, seq_len, head_dim)  # num_kv_heads = 4
        
        # This should work without error and use the corrected mrope_section logic
        try:
            q_embed, k_embed = apply_multimodal_rotary_pos_emb(
                q, k, cos, sin, original_section, unsqueeze_dim=1
            )
            print("✓ Fixed mrope_section behavior works correctly")
            print(f"  Original: {original_section}")
            print(f"  After * 2: {original_section * 2}")
            print(f"  Output shapes - q_embed: {q_embed.shape}, k_embed: {k_embed.shape}")
            
        except Exception as e:
            pytest.fail(f"Fixed mrope_section behavior failed: {e}")


if __name__ == "__main__":
    # Run a quick test when called directly
    print("=== Quick MRoPE Test ===")
    
    # Test tensor loading directly (not using fixtures)
    modalities = ["text_only", "text_image", "text_video"]
    
    for modality in modalities:
        print(f"\n--- Testing {modality} ---")
        tensors_path = f"/mnt/vast/home/lawrence/tensors/{modality}"
        
        required_tensors = [
            "position_ids", "rope_input_x", "rope_input_position_ids", 
            "rope_output_cos_sin", "position_embeddings", "mrope_input_q",
            "mrope_input_k", "mrope_input_cos", "mrope_input_sin", 
            "mrope_section", "q_embed", "k_embed"
        ]
        
        try:
            # Try to load each tensor
            loaded_tensors = {}
            for tensor_name in required_tensors:
                tensor_path = f"{tensors_path}/{tensor_name}.pt"
                loaded_tensors[tensor_name] = torch.load(tensor_path)
                print(f"✓ Loaded {tensor_name}: {loaded_tensors[tensor_name].shape if hasattr(loaded_tensors[tensor_name], 'shape') else type(loaded_tensors[tensor_name])}")
            
            print(f"✓ All {len(required_tensors)} reference tensors loaded for {modality}")
            
        except FileNotFoundError as e:
            print(f"⚠ Tensors not found for {modality}: {e}")
            print(f"  Run test_run.py to generate reference tensors")
        except Exception as e:
            print(f"✗ Unexpected error for {modality}: {e}")
    
    print("\n✓ Quick test complete - ready for pytest!") 